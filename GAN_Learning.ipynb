{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timlovescoding/Learning_about_GAN/blob/master/GAN_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhB0WyUymQRX",
        "colab_type": "code",
        "outputId": "23556486-1f2d-4de2-86ed-8447e2b3e7f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        }
      },
      "source": [
        "## Learning about GAN from book written by Francois Chollet\n",
        "\n",
        "\n",
        "# 1) Building the generator:\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "latent_dim = 32 #dimension of latent space\n",
        "\n",
        "# Generate 32x32x3 image~\n",
        "height   = 32\n",
        "width    = 32\n",
        "channels = 3\n",
        "\n",
        "#Setting up Neural Network for Generator:\n",
        "\n",
        "gen_input = keras.Input(shape=(latent_dim,))  #Input to generator\n",
        "\n",
        "x = layers.Dense(16*16*128)(gen_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape((16,16,128))(x)\n",
        "\n",
        "x = layers.Conv2D(256,5, padding = 'same')(x) # 5x5 Kernel, 256 filters, same padding\n",
        "x = layers.LeakyReLU()(x)\n",
        " \n",
        "x = layers.Conv2DTranspose(256,4,strides = 2, padding = 'same')(x)   #Upsampling (Reverse Convolution)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2D(256,5,padding = 'same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256,5,padding = 'same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2D(channels,7,activation = 'tanh', padding='same')(x)\n",
        "\n",
        "generator = models.Model(gen_input,x)\n",
        "generator.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0825 12:27:56.299717 139799833900928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0825 12:27:56.334737 139799833900928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0825 12:27:56.343086 139799833900928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32768)             1081344   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 256)       819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 3)         37635     \n",
            "=================================================================\n",
            "Total params: 6,264,579\n",
            "Trainable params: 6,264,579\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lp1Llc8rGad",
        "colab_type": "code",
        "outputId": "c381ee50-b3dc-454a-b0ad-3ec18d2846ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        }
      },
      "source": [
        "# 2) Building the discriminator:\n",
        "\n",
        "\n",
        "dis_input = layers.Input(shape=(height,width,channels))\n",
        "\n",
        "x = layers.Conv2D(128,3)(dis_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128,4,strides = 2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128,4,strides = 2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128,4,strides = 2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "x = layers.Dropout(0.4)(x) # important to use dropout or else gradient may vanished easily\n",
        "\n",
        "x = layers.Dense(1,activation = 'sigmoid')(x) # 0 or 1 Classification (Fake or Real)\n",
        "\n",
        "discriminator = models.Model(dis_input,x)\n",
        "discriminator.summary()\n",
        "\n",
        "from keras import optimizers\n",
        "\n",
        "dis_optimizer = optimizers.RMSprop(lr = 0.0008, clipvalue = 1.0, decay =1e-8)\n",
        "discriminator.compile(optimizer = dis_optimizer ,  loss = \"binary_crossentropy\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0825 12:27:56.511124 139799833900928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0825 12:27:56.517534 139799833900928 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0825 12:27:56.552984 139799833900928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0825 12:27:56.557825 139799833900928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0825 12:27:56.562426 139799833900928 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 30, 30, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 14, 14, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 6, 6, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 2, 2, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 790,913\n",
            "Trainable params: 790,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvTeSjmjwaS_",
        "colab_type": "code",
        "outputId": "e4f6efd4-a30b-4901-b1fe-de494d5f459d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "# 3) The adversarial network: (Generator trying to fool the discriminator)\n",
        "\n",
        "\n",
        "discriminator.trainable = False #Applying only to the GAN model (Do not want to train discriminator to always predict REAL)\n",
        "\n",
        "gan_input = keras.Input(shape = (latent_dim,)) \n",
        "\n",
        "gan_output = discriminator(generator(gan_input)) #Generated data feed into discriminator\n",
        "\n",
        "gan = models.Model(gan_input, gan_output)\n",
        "\n",
        "gan_optimizer = optimizers.RMSprop( lr=0.0004, clipvalue = 1.0, decay = 1e-8)\n",
        "gan.compile(optimizer =  gan_optimizer, loss =\"binary_crossentropy\") #Output is discriminator (binary loss function)\n",
        "\n",
        "\n",
        "\n",
        "gan.summary() #Trainable Params: The generator.\n",
        "              #Non-trainable params: The discriminator\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "model_1 (Model)              (None, 32, 32, 3)         6264579   \n",
            "_________________________________________________________________\n",
            "model_2 (Model)              (None, 1)                 790913    \n",
            "=================================================================\n",
            "Total params: 7,055,492\n",
            "Trainable params: 6,264,579\n",
            "Non-trainable params: 790,913\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf31v2771CNe",
        "colab_type": "code",
        "outputId": "8599ec5a-c480-402f-ad55-e8cfb72b8ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "# Training the GAN:\n",
        "\n",
        "# 1. Draw random points in the latent space\n",
        "# 2. Generate images with generator using these random points (Generated Image Set)\n",
        "# 3. Mix the generated images with real ones (Mixed Image set)\n",
        "# 4. Train discriminator using the Mixed Image set (Binary loss function: Real or Fake)\n",
        "# 5. Draw new random points in the latent space\n",
        "# 6. Train the adversial network using these random vectors with target to Real Images\n",
        "#    -Update weights of generator till the generator is able to fool the discriminator\n",
        "#    -Discriminator weight is frozen in GAN model\n",
        "\n",
        "###################################################################\n",
        "\n",
        "# 4) Getting the datasets for real images:\n",
        "\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train , y_train) , (_,_) = cifar10.load_data()\n",
        "\n",
        "print(\"Training size\" + str(x_train.shape))\n",
        "print(\"Label size\" + str(y_train.shape))\n",
        "print(y_train.flatten())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "Training size(50000, 32, 32, 3)\n",
            "Label size(50000, 1)\n",
            "[6 9 9 ... 9 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fld84_xnBjk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting real images from CIFAR 10\n",
        "\n",
        "x_train = x_train[ y_train.flatten() == 6 ] #Class 6 is all of the frogs\n",
        "\n",
        "x_train= x_train.reshape((x_train.shape[0],) + (height,width,channels)) # 5000 samples (32x32x3)\n",
        "\n",
        "x_train= x_train/255.0 # Normalize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww2iav-7B44y",
        "colab_type": "code",
        "outputId": "f106c91b-02d0-47bd-ff99-856e5f084018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "# 5) Setting up training\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.preprocessing import image\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "my_dir = '/content/gdrive/My Drive/GAN_IMAGES_1'   #Set up your own directory in Google Drive (using colaboratory to run my code)\n",
        "\n",
        "iterations = 15000\n",
        "batch_size = 50\n",
        "\n",
        "start = 0\n",
        "\n",
        "for step in range(iterations):\n",
        "  \n",
        "  random_latent_vectors = np.random.normal(size =(batch_size,latent_dim))  # Samples of random points in the latent space\n",
        "  \n",
        "  generated_images =  generator.predict(random_latent_vectors)  #Decoding into fake images through GENERATOR NN\n",
        "# Generated images are of batch size 20x32x32x3\n",
        "\n",
        "  stop = start  + batch_size\n",
        "  real_images = x_train[start:stop]\n",
        "  combined_images = np.concatenate([generated_images, real_images],axis=0) # Shape = (40,32,32,3) 40 because 20+20 from both image set\n",
        "\n",
        "\n",
        "#Fixing the label onto the images:\n",
        "\n",
        "  labels = np.concatenate([np.ones((generated_images.shape[0],1)) , np.zeros((real_images.shape[0],1))]) # 1 for generated, 0 for real\n",
        "  # Label shape = (40,1)\n",
        "\n",
        "#*** Add random noise into labels (Trick for training)\n",
        "\n",
        "  labels = labels + 0.065*np.random.random(labels.shape)\n",
        "  \n",
        "# 6) Train the Discriminator:\n",
        "\n",
        "  dis_loss = discriminator.train_on_batch(combined_images,labels)\n",
        "\n",
        "\n",
        "  random_latent_vectors = np.random.normal(size= (batch_size,latent_dim))\n",
        "  \n",
        "  misleading_targets = np.zeros((batch_size,1))\n",
        "  \n",
        "  adv_loss = gan.train_on_batch(random_latent_vectors,misleading_targets) #note: discriminator is frozen in GAN Model\n",
        "  \n",
        "  \n",
        "  start = start + batch_size\n",
        "  \n",
        "  if start > (len(x_train) - batch_size):\n",
        "    start = 0\n",
        "    \n",
        "  if step % 1000 == 0:\n",
        "    \n",
        "    gan.save_weights('gan.h5')\n",
        "    \n",
        "    print('Discriminator Loss:' , dis_loss)\n",
        "    print('Adversarial Loss:', adv_loss)\n",
        "    \n",
        "    img =  image.array_to_img(generated_images[0] * 255.0, scale = False)\n",
        "    img.save(os.path.join(my_dir,'generated_frog' + str(step)+ '.png'))\n",
        "    \n",
        " \n",
        "    img =  image.array_to_img(real_images[0] * 255.0, scale = False)\n",
        "    img.save(os.path.join(my_dir,'real_frog' + str(1)+ '.png'))\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "   \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Discriminator Loss: 0.6805521\n",
            "Adversarial Loss: 0.6801954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Discriminator Loss: 0.69642174\n",
            "Adversarial Loss: 0.7566668\n",
            "Discriminator Loss: 0.69223726\n",
            "Adversarial Loss: 0.78600234\n",
            "Discriminator Loss: 0.69282943\n",
            "Adversarial Loss: 0.77431357\n",
            "Discriminator Loss: 0.6945237\n",
            "Adversarial Loss: 0.7724354\n",
            "Discriminator Loss: 0.7035577\n",
            "Adversarial Loss: 0.7865812\n",
            "Discriminator Loss: 0.68808055\n",
            "Adversarial Loss: 0.764144\n",
            "Discriminator Loss: 0.68804413\n",
            "Adversarial Loss: 0.7524828\n",
            "Discriminator Loss: 0.69160044\n",
            "Adversarial Loss: 0.7663623\n",
            "Discriminator Loss: 0.69707\n",
            "Adversarial Loss: 0.7428724\n",
            "Discriminator Loss: 0.69034934\n",
            "Adversarial Loss: 0.76276034\n",
            "Discriminator Loss: 0.68691176\n",
            "Adversarial Loss: 0.78465956\n",
            "Discriminator Loss: 0.6928648\n",
            "Adversarial Loss: 0.7506774\n",
            "Discriminator Loss: 0.7031819\n",
            "Adversarial Loss: 0.84559166\n",
            "Discriminator Loss: 0.7062076\n",
            "Adversarial Loss: 0.8469773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTivTWhvCjRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sL9QsLdFz-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVT_4y3_HbP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob_oV5lag1wN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDKU5LX1hmxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeJsiFbKh_3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}